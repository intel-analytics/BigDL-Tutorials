{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will unveil the basic mechanism of the computational process of BigDL using a simple example. In this example, we show that how to obtain the gradients with a single forward and backward pass for updating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import the necessary modules and initialize the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "import org.apache.spark.SparkContext\n",
    "\n",
    "import com.intel.analytics.bigdl.nn._\n",
    "import com.intel.analytics.bigdl.utils.{Engine, LoggerFilter, T, Table}\n",
    "import com.intel.analytics.bigdl.nn.{AbsCriterion}\n",
    "import com.intel.analytics.bigdl.tensor._\n",
    "import com.intel.analytics.bigdl.numeric.NumericFloat\n",
    "\n",
    "Engine.init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a simple linear regression which can be formulized as *y = Wx + b*ï¼Œ where *W = [w1,w2]* are weight parameters and *b* is the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight and Bias:\n",
      "0.3978135\t-0.2532979\t\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n",
      "0.66053367\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n",
      "GradWeight and gradBias:\n",
      "0.0\t0.0\t\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n",
      "0.0\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n"
     ]
    }
   ],
   "source": [
    "// the input data size is 2*1, the output size is 1*1\n",
    "val linear = Linear(2, 1)\n",
    "// print the randomly initialized parameters\n",
    "val (param1, param2) = linear.parameters()\n",
    "println(\"Weight and Bias:\")\n",
    "param1.foreach(println)\n",
    "println(\"GradWeight and gradBias:\")\n",
    "param2.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.564943"
     ]
    }
   ],
   "source": [
    "val input = Tensor(T(T(1f, -2f)))\n",
    "// forward to output\n",
    "val output = linear.updateOutput(input)\n",
    "print(output.valueAt(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we backpropagate the error of the predicted output to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.564943\n",
      "Weight and Bias:\n",
      "0.3978135\t-0.2532979\t\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n",
      "0.66053367\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n",
      "GradWeight and gradBias:\n",
      "0.0\t0.0\t\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n",
      "0.0\n",
      "[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n"
     ]
    }
   ],
   "source": [
    "// mean absolute error\n",
    "val mae = AbsCriterion()\n",
    "val target = Tensor(1).fill(0)\n",
    "\n",
    "val loss = mae.updateOutput(output, target)\n",
    "printf(\"loss: %s\\n\", loss.toString)\n",
    "        \n",
    "val gradOutput = mae.updateGradInput(output, target)\n",
    "linear.updateGradInput(input, gradOutput)\n",
    "\n",
    "val (param1, param2) = linear.parameters()\n",
    "println(\"Weight and Bias:\")\n",
    "param1.foreach(println)\n",
    "println(\"GradWeight and gradBias:\")\n",
    "param2.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the Spark should be stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that the backward pass has computed the gradient of the weights in respect to the loss. Therefore we can update the weights with the gradients using algorithms such as *stochastic gradient descent*. However in practice you **should** use *optimizer.optimize()* to circumvent the details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
