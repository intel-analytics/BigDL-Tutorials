{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will introduce how to use BigDL to train to a simple linear regression model. The first thing we need to do it to import necessary packages and inilialize the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "import org.apache.spark.SparkContext\n",
    "\n",
    "import com.intel.analytics.bigdl._\n",
    "import com.intel.analytics.bigdl.utils.{Engine, LoggerFilter, T, Table}\n",
    "import com.intel.analytics.bigdl.dataset.{DataSet, Sample}\n",
    "import com.intel.analytics.bigdl.nn.{Sequential, Linear, MSECriterion}\n",
    "import com.intel.analytics.bigdl.optim._\n",
    "import com.intel.analytics.bigdl.models.lenet.Utils._\n",
    "import com.intel.analytics.bigdl.optim.{SGD, Top1Accuracy}\n",
    "import com.intel.analytics.bigdl.tensor._\n",
    "import com.intel.analytics.bigdl.numeric.NumericFloat\n",
    "\n",
    "Engine.init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we randomly create datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val featuresDim = 2\n",
    "val dataLen = 100\n",
    "\n",
    "def GetRandSample() = {\n",
    "    val features = Tensor(featuresDim).rand(0, 1)\n",
    "    val label = (0.4 + features.sum * 2).toFloat\n",
    "    val sample = Sample[Float](features, label)\n",
    "    sample\n",
    "}\n",
    "\n",
    "val rddTrain = sc.parallelize(0 until dataLen).map(_ => GetRandSample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then we specify the necessary parameters and construct a linear regression model using BigDL. Please notice that batch_size should be devided by the number of cores you use. In this example, it was set as 8 since there are 4 cores when running the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Parameters\n",
    "val learningRate = 0.2\n",
    "val trainingEpochs = 5\n",
    "val batchSize = 4\n",
    "val nInput = featuresDim\n",
    "val nOutput = 1 \n",
    "\n",
    "def LinearRegression(nInput: Int, nOutput: Int) = {\n",
    "    // Initialize a sequential container\n",
    "    val model = Sequential()\n",
    "    // Add a linear layer\n",
    "    model.add(Linear(nInput, nOutput))\n",
    "    model\n",
    "}\n",
    "\n",
    "val model = LinearRegression(nInput, nOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct the optimizer to optimize the linear regression problem. You can specific your own learning rate in $SGD()$ method, also, you can replace the $SGD()$ with other optimizer such like $Adam()$. Click [here](https://github.com/intel-analytics/BigDL/tree/master/spark/dl/src/main/scala/com/intel/analytics/bigdl/optim) to see more optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.intel.analytics.bigdl.optim.DistriOptimizer@2ec4ba5b"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val optimizer = Optimizer(model = model, sampleRDD = rddTrain, criterion = MSECriterion[Float](), batchSize = batchSize)\n",
    "optimizer.setOptimMethod(new SGD(learningRate=learningRate))\n",
    "optimizer.setEndWhen(Trigger.maxEpoch(trainingEpochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Start to train\n",
    "val trainedModel = optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict result:\n",
      "3.7649865,2.7541423,1.9586959,1.5578532,3.7649865\n"
     ]
    }
   ],
   "source": [
    "val predictResult = trainedModel.predict(rddTrain)\n",
    "val p = predictResult.take(5).map(_.toTensor.valueAt(1)).mkString(\",\")\n",
    "println(\"Predict result:\")\n",
    "println(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the trained model, we construct a dataset for testing and print the result of _Mean Square Error_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.747768\n"
     ]
    }
   ],
   "source": [
    "val r = new scala.util.Random(100)\n",
    "val totalLength = 10\n",
    "val features = Tensor(totalLength, featuresDim).rand(0, 1)\n",
    "var label = (0.4 + features.sum).toFloat\n",
    "val prediction = sc.parallelize(0 until totalLength).map(r => Sample[Float](features(r + 1), label))\n",
    "val predictResult = trainedModel.predict(prediction)\n",
    "val p = predictResult.take(6).map(_.toTensor.valueAt(1))\n",
    "val groundLabel = Tensor(T(\n",
    "                    | T(-0.47596836f),\n",
    "                    | T(-0.37598032f),\n",
    "                    | T(-0.00492062f),\n",
    "                    | T(-0.5906958f),\n",
    "                    | T(-0.12307882f),\n",
    "                    | T(-0.77907401f)))\n",
    "\n",
    "var mse = 0f\n",
    "for (i <- 1 to 6) {\n",
    "    mse += (p(i - 1) - groundLabel(i).valueAt(1)) * (p(i - 1) - groundLabel(i).valueAt(1))\n",
    "}\n",
    "mse /= 6f\n",
    "println(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we stop the Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
