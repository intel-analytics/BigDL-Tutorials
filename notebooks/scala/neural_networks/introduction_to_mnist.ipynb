{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the MNIST database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following tutorials, we are going to use the MNIST database of handwritten digits. MNIST is a simple computer vision dataset of handwritten digits. It has 60,000 training examles and 10,000 test examples. \"It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\" For more details of this database, please checkout the website [MNIST](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In BigDL, we need to write a function to download and read the MNIST data when using Scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import java.nio.ByteBuffer\n",
    "import java.nio.file.{Files, Path, Paths}\n",
    "\n",
    "import com.intel.analytics.bigdl.dataset.ByteRecord\n",
    "import com.intel.analytics.bigdl.utils.File\n",
    "import scopt.OptionParser\n",
    "\n",
    "def load(featureFile: String, labelFile: String): Array[ByteRecord] = {\n",
    "    val featureBuffer = ByteBuffer.wrap(Files.readAllBytes(Paths.get(featureFile)))\n",
    "    val labelBuffer = ByteBuffer.wrap(Files.readAllBytes(Paths.get(labelFile)))\n",
    "    \n",
    "    val labelMagicNumber = labelBuffer.getInt()\n",
    "    require(labelMagicNumber == 2049)\n",
    "    val featureMagicNumber = featureBuffer.getInt()\n",
    "    require(featureMagicNumber == 2051)\n",
    "\n",
    "    val labelCount = labelBuffer.getInt()\n",
    "    val featureCount = featureBuffer.getInt()\n",
    "    require(labelCount == featureCount)\n",
    "\n",
    "    val rowNum = featureBuffer.getInt()\n",
    "    val colNum = featureBuffer.getInt()\n",
    "\n",
    "    val result = new Array[ByteRecord](featureCount)\n",
    "    var i = 0\n",
    "    while (i < featureCount) {\n",
    "      val img = new Array[Byte]((rowNum * colNum))\n",
    "      var y = 0\n",
    "      while (y < rowNum) {\n",
    "        var x = 0\n",
    "        while (x < colNum) {\n",
    "          img(x + y * colNum) = featureBuffer.get()\n",
    "          x += 1\n",
    "        }\n",
    "        y += 1\n",
    "      }\n",
    "      result(i) = ByteRecord(img, labelBuffer.get().toFloat + 1.0f)\n",
    "      i += 1\n",
    "    }\n",
    "\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the necessary packages and initialize the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "import org.apache.spark.SparkContext\n",
    "\n",
    "import com.intel.analytics.bigdl.utils._\n",
    "import com.intel.analytics.bigdl.dataset.DataSet\n",
    "import com.intel.analytics.bigdl.dataset.image.{BytesToGreyImg, GreyImgNormalizer, GreyImgToBatch, GreyImgToSample}\n",
    "import com.intel.analytics.bigdl.nn.{ClassNLLCriterion, Module}\n",
    "import com.intel.analytics.bigdl.models.lenet.Utils._\n",
    "import com.intel.analytics.bigdl.nn.{ClassNLLCriterion, Linear, LogSoftMax, Sequential, Reshape}\n",
    "import com.intel.analytics.bigdl.numeric.NumericFloat\n",
    "import com.intel.analytics.bigdl.optim.{SGD, Top1Accuracy}\n",
    "import com.intel.analytics.bigdl.utils.{Engine, LoggerFilter, T, Table}\n",
    "import com.intel.analytics.bigdl.tensor.Tensor\n",
    "\n",
    "Engine.init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the paths of training data and validation data should be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val trainData = \"../datasets/mnist/train-images-idx3-ubyte\"\n",
    "val trainLabel = \"../datasets/mnist/train-labels-idx1-ubyte\"\n",
    "val validationData = \"../datasets/mnist/t10k-images-idx3-ubyte\"\n",
    "val validationLabel = \"../datasets/mnist/t10k-labels-idx1-ubyte\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then, we need to define some parameters for loading the MINST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Parameters\n",
    "val batchSize = 2048\n",
    "val learningRate = 0.2\n",
    "val maxEpochs = 15\n",
    "\n",
    "//Network Parameters\n",
    "val nInput = 784 //MNIST data input (img shape: 28*28)\n",
    "val nClasses = 10  //MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use predefined function to load and serialize MNIST data. If you want to output the data, some modifications on the funtion should be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainSet = \n",
    "    DataSet.array(load(trainData, trainLabel), sc) -> BytesToGreyImg(28, 28) -> GreyImgNormalizer(trainMean, trainStd) -> GreyImgToBatch(batchSize)\n",
    "val validationSet = \n",
    "    DataSet.array(load(validationData, validationLabel), sc) -> BytesToGreyImg(28, 28) -> GreyImgNormalizer(testMean, testStd) -> GreyImgToBatch(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
